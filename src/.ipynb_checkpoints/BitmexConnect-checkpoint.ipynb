{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import logging\n",
    "import queue\n",
    "import random\n",
    "import threading\n",
    "import time\n",
    "\n",
    "class Pipeline(queue.Queue):\n",
    "    def __init__(self):\n",
    "        super().__init__(maxsize=10)\n",
    "\n",
    "    def get_message(self, name):\n",
    "        logging.debug(\"%s:about to get from queue\", name)\n",
    "        value = self.get()\n",
    "        logging.debug(\"%s:got %d from queue\", name, value)\n",
    "        return value\n",
    "\n",
    "    def set_message(self, value, name):\n",
    "        logging.debug(\"%s:about to add %d to queue\", name, value)\n",
    "        self.put(value)\n",
    "        logging.debug(\"%s:added %d to queue\", name, value)\n",
    "\n",
    "SENTINEL = object()\n",
    "\n",
    "def producer(pipeline, event):\n",
    "    \"\"\"Pretend we're getting a number from the network.\"\"\"\n",
    "    while not event.is_set():\n",
    "        message = random.randint(1, 101)\n",
    "        logging.info(\"Producer got message: %s\", message)\n",
    "        pipeline.set_message(message, \"Producer\")\n",
    "\n",
    "    logging.info(\"Producer received EXIT event. Exiting\")\n",
    "    \n",
    "    \n",
    "def consumer(pipeline, event):\n",
    "    \"\"\"Pretend we're saving a number in the database.\"\"\"\n",
    "    while not event.is_set() or not pipeline.empty():\n",
    "        message = pipeline.get_message(\"Consumer\")\n",
    "        logging.info(\n",
    "            \"Consumer storing message: %s  (queue size=%s)\",\n",
    "            message,\n",
    "            pipeline.qsize(),\n",
    "        )\n",
    "\n",
    "    logging.info(\"Consumer received EXIT event. Exiting\")\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    format = \"%(asctime)s: %(message)s\"\n",
    "    logging.basicConfig(format=format, level=logging.INFO,\n",
    "                        datefmt=\"%H:%M:%S\")\n",
    "    # logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "    pipeline = Pipeline()\n",
    "    event = threading.Event()\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        executor.submit(producer, pipeline, event)\n",
    "        executor.submit(consumer, pipeline, event)\n",
    "\n",
    "        time.sleep(0.1)\n",
    "        logging.info(\"Main: about to set event\")\n",
    "        event.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import queue\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='(%(threadName)-9s) %(message)s',)\n",
    "\n",
    "BUF_SIZE = 10\n",
    "q = queue.Queue(BUF_SIZE)\n",
    "\n",
    "class ProducerThread(threading.Thread):\n",
    "    def __init__(self, group=None, target=None, name=None,\n",
    "                 args=(), kwargs=None, verbose=None):\n",
    "        super(ProducerThread,self).__init__()\n",
    "        self.target = target\n",
    "        self.name = name\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            if not q.full():\n",
    "                item = random.randint(1,10)\n",
    "                q.put(item)\n",
    "                logging.debug('Putting ' + str(item)  \n",
    "                              + ' : ' + str(q.qsize()) + ' items in queue')\n",
    "                time.sleep(random.random())\n",
    "        return\n",
    "\n",
    "class ConsumerThread(threading.Thread):\n",
    "    def __init__(self, group=None, target=None, name=None,\n",
    "                 args=(), kwargs=None, verbose=None):\n",
    "        super(ConsumerThread,self).__init__()\n",
    "        self.target = target\n",
    "        self.name = name\n",
    "        return\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            if not q.empty():\n",
    "                item = q.get()\n",
    "                logging.debug('Getting ' + str(item) \n",
    "                              + ' : ' + str(q.qsize()) + ' items in queue')\n",
    "                time.sleep(random.random())\n",
    "        return\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    p = ProducerThread(name='producer')\n",
    "    c = ConsumerThread(name='consumer')\n",
    "\n",
    "    p.start()\n",
    "    time.sleep(2)\n",
    "    c.start()\n",
    "    time.sleep(2)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import websocket\n",
    "import bitmex_websocket as bm_ws\n",
    "from bitmex_websocket import Instrument\n",
    "from bitmex_websocket.constants import InstrumentChannels\n",
    "from threading import Thread\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "class BitmexSubscriber:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.subscriptions = {}\n",
    "\n",
    "        self._message_handlers = {'trade': self._log_trade, 'quote': self._log_quote}\n",
    "        self._buffers = {'trade':[], 'quote':[]}\n",
    "\n",
    "\n",
    "    def archive(self):\n",
    "        ref = self._buffers['trade']\n",
    "        if len(ref) > 10:\n",
    "            with open('XBTUSD2-trades.pkl', 'ab', buffering=10*1024) as f:\n",
    "                pickle.dump(ref, f, pickle.HIGHEST_PROTOCOL)\n",
    "            ref.clear()\n",
    "            \n",
    "        ref = self._buffers['quote']\n",
    "        if len(ref) > 10:\n",
    "            with open('XBTUSD2-quotes.pkl', 'ab', buffering=10*1024) as f:\n",
    "                pickle.dump(ref, f, pickle.HIGHEST_PROTOCOL)\n",
    "            ref.clear()\n",
    "            \n",
    "        \n",
    "    def ingest_data(self, filename, data_dict):\n",
    "        with open(f'{filename}.pkl', 'ab') as f:\n",
    "            pickle.dump(data_dict, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def _log_trade(self, msg):\n",
    "        self._buffers['trade'].append(msg['data'])\n",
    "        #for item in msg['data']:\n",
    "            #self.ingest_data(f\"{item['symbol']}-trades\", item)\n",
    "\n",
    "    def _log_quote(self, msg):\n",
    "        self._buffers['quote'].append(msg['data'])\n",
    "        #for item in msg['data']:\n",
    "            #self.ingest_data(f\"{item['symbol']}-quotes\", item)        \n",
    "\n",
    "    def on_message(self, msg):\n",
    "        print(len(self._buffers['trade']), len(self._buffers['quote']))\n",
    "        #tmp = len(msg['data'])\n",
    "        #print(f'Rec message {tmp}')\n",
    "        #time.sleep(10.0)\n",
    "        \n",
    "        table = msg['table']\n",
    "        handler = self._message_handlers[table]\n",
    "        handler(msg)\n",
    "        self.archive()\n",
    "\n",
    "    def subscribe(self, symbol, channels):\n",
    "\n",
    "        instrument = bm_ws.Instrument(symbol=symbol, channels=channels)\n",
    "        instrument.on('action', lambda msg: self.on_message(msg))\n",
    "        thread = Thread(target=instrument.run_forever)\n",
    "        self.subscriptions.update({symbol: {'channels': channels, 'thread': thread}})\n",
    "        thread.start()\n",
    "\n",
    "\n",
    "def bitmex_subscribe():\n",
    "\n",
    "    websocket.enableTrace(True)\n",
    "\n",
    "    channels = [\n",
    "        InstrumentChannels.trade, InstrumentChannels.quote\n",
    "    ]\n",
    "    #InstrumentChannels.trade\n",
    "\n",
    "    subscriber = BitmexSubscriber()\n",
    "    subscriber.subscribe('XBTUSD', channels)\n",
    "\n",
    "bitmex_subscribe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import datetime\n",
    "import itertools\n",
    "\n",
    "timezero = datetime.datetime(2021, 1, 1, 8, 0, 0)\n",
    "\n",
    "ncalls = 0\n",
    "\n",
    "def rec_data():\n",
    "    global ncalls\n",
    "    ncalls += 1\n",
    "    time = timezero + ncalls*datetime.timedelta(hours=3)\n",
    "    return {'Timestamp': str(time), 'Hdr1': np.random.rand()}\n",
    "\n",
    "\n",
    "buffer = []\n",
    "cnt = 0\n",
    "while True:\n",
    "    buffer.append(rec_data())\n",
    "    \n",
    "    if cnt % 10 == 0:\n",
    "        for key, group in itertools.groupby(buffer, lambda x: datetime.datetime.strptime(x['Timestamp'], '%Y%m%d')):\n",
    "            print(key, group)\n",
    "        #with open('C:\\\\TEMP\\\\2BUPL\\\\')\n",
    "    \n",
    "    \n",
    "    cnt += 1\n",
    "    if cnt > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#import gzip\n",
    "#import numpy as np\n",
    "import datetime\n",
    "import itertools\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "timezero = datetime.datetime(2021, 1, 1, 8, 0, 0)\n",
    "curr_time = timezero\n",
    "last_upload = None\n",
    "DATE_FORMAT = '%Y%m%d %H:%M:%S'\n",
    "\n",
    "\n",
    "def rec_data():\n",
    "    return {'Timestamp': curr_time.strftime(DATE_FORMAT), 'Hdr1': np.random.rand()}\n",
    "\n",
    "last_cleanup = None\n",
    "class Buffer:\n",
    "    def __init__(self):\n",
    "        self._buff = []\n",
    "    \n",
    "    def write_buffer(self):\n",
    "        # group buffer records on date (assumed to be chronologically sorted)\n",
    "        for key, group in itertools.groupby(self._buff, lambda x: datetime.datetime.strptime(x['Timestamp'], DATE_FORMAT).strftime('%Y%m%d')):\n",
    "            records = list(group)\n",
    "            with open('C:\\\\temp\\\\2BUPL\\\\{}_XBT_quote'.format(key), 'ab+') as f:\n",
    "                print('writing {} records to {}'.format(len(records), key))\n",
    "                pickle.dump(records, f, pickle.HIGHEST_PROTOCOL)\n",
    "        self._buff = [] # empty buffer\n",
    "        \n",
    "    def append(self, records):\n",
    "        self._buff.append(records)\n",
    "        \n",
    "    def size(self):\n",
    "        return len(self._buff)\n",
    "\n",
    "cnt = 0\n",
    "buffer = Buffer()\n",
    "while True:\n",
    "    print('----------------')\n",
    "    print('Time is now {}'.format(curr_time))\n",
    "    buffer.append(rec_data())\n",
    "    print('size(buffer) = {}'.format(buffer.size()))\n",
    "    \n",
    "    # Oly write to local disc in chunks\n",
    "    if cnt % 10 == 0:\n",
    "        buffer.write_buffer()\n",
    "        \n",
    "        \n",
    "    if last_cleanup is None or curr_time.date() > last_cleanup:\n",
    "        buffer.write_buffer()\n",
    "        # Check if upload time (buffer must be empty here)..\n",
    "        for fullpath in glob.glob('C:\\\\temp\\\\2BUPL\\\\*_XBT_quote*'):\n",
    "            filename = os.path.basename(fullpath)\n",
    "            fileanchor = datetime.datetime.strptime(filename[0:8], '%Y%m%d')\n",
    "            if curr_time.date() > fileanchor.date():\n",
    "                # Upload and move to uploaded local dir...\n",
    "                new_path = '{}{}'.format('C:\\\\temp\\\\UPL\\\\', filename)\n",
    "                print('moving from {} to {}'.format(fullpath, new_path))\n",
    "                shutil.move(fullpath, new_path)\n",
    "                \n",
    "        # Check if delete time.\n",
    "        for fullpath in glob.glob('C:\\\\temp\\\\UPL\\\\*_XBT_quote*'):\n",
    "            filename = os.path.basename(fullpath)\n",
    "            fileanchor = datetime.datetime.strptime(filename[0:8], '%Y%m%d')\n",
    "            if fileanchor.date() < curr_time.date() - datetime.timedelta(days=3):\n",
    "                print('deleting old file {}'.format(fullpath))\n",
    "                os.remove(fullpath)\n",
    "                \n",
    "        last_cleanup = curr_time.date()\n",
    "                \n",
    "                \n",
    "    curr_time += datetime.timedelta(hours=3)\n",
    "    \n",
    "    cnt += 1\n",
    "    if cnt > 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clear():\n",
    "    open('C:\\\\TEMP\\\\foo1.txt', 'w').close()\n",
    "    open('C:\\\\TEMP\\\\foo2.txt', 'w').close()\n",
    "\n",
    "def foo1():\n",
    "    for i in range(100):\n",
    "        with open('C:\\\\TEMP\\\\foo1.txt', 'a+') as f:\n",
    "            f.write(str(i) +'\\n')\n",
    "    return\n",
    "            \n",
    "def foo2():\n",
    "    f = open('C:\\\\TEMP\\\\foo2.txt', 'a+')\n",
    "    for i in range(100):\n",
    "        f.write(str(i) +'\\n')\n",
    "    #f.close()\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear()\n",
    "%timeit foo1()\n",
    "%timeit foo2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of File\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "src = r\"C:\\Users\\Pontus\\Documents\\GitHub\\microprice\\XBTUSD-quotes.pickle\"\n",
    "data = []\n",
    "cnt = 0\n",
    "with open(src, 'rb') as f:\n",
    "    try:\n",
    "        while True:\n",
    "            data.append(pickle.load(f))\n",
    "            cnt += 1\n",
    "    except EOFError:\n",
    "        print('End of File')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "def clear():\n",
    "    for x in glob.glob('C:\\\\TEMP\\\\*.pklz'):\n",
    "        open(x, 'w').close()\n",
    "    \n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def bar1(seq, n): # open once, chunk dicts gzip\n",
    "    f_hnd = gzip.open('C:\\\\TEMP\\\\default.pklz', 'ab+')\n",
    "    for cnk in chunks(seq, n):\n",
    "        pickle.dump(cnk, f_hnd)    \n",
    "        #time.sleep(0.5)\n",
    "    f_hnd.close()\n",
    "    return\n",
    "\n",
    "def bar1R(): # open once, chunk dicts gzip\n",
    "    bla = []\n",
    "    with gzip.open('C:\\\\TEMP\\\\default.pklz', 'rb') as f_hnd:\n",
    "        try:\n",
    "            while True:\n",
    "                bla.append(pickle.load(f_hnd))\n",
    "        except:\n",
    "            pass\n",
    "    return\n",
    "\n",
    "def bar2(seq, n): # open once, chunk dicts gzip\n",
    "    f_hnd = gzip.open('C:\\\\TEMP\\\\default_json.pklz', 'wt+')\n",
    "    for x in seq:\n",
    "        f_hnd.writelines(str(x))\n",
    "    f_hnd.close()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNKSIZE = 1000\n",
    "clear()\n",
    "%timeit -n1 -r1 bar1(data, CHUNKSIZE)\n",
    "%timeit -n1 -r1 bar2(data, CHUNKSIZE)\n",
    "#%timeit -n1 -r1 bar4(data, CHUNKSIZE)\n",
    "#%timeit -n1 -r1 bar5(data[0:10000], CHUNKSIZE) # Open each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "malformed node or string: <ast.Subscript object at 0x00000207FA69EAC0>\n",
      "0\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "#bar2(data[0:10], 1)\n",
    "bar2R()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': '2020-12-14T00:07:24.057Z',\n",
       "  'symbol': 'XBTUSD',\n",
       "  'bidSize': 83434,\n",
       "  'bidPrice': 19077,\n",
       "  'askPrice': 19077.5,\n",
       "  'askSize': 890861},\n",
       " {'timestamp': '2020-12-14T00:07:24.072Z',\n",
       "  'symbol': 'XBTUSD',\n",
       "  'bidSize': 83434,\n",
       "  'bidPrice': 19077,\n",
       "  'askPrice': 19077.5,\n",
       "  'askSize': 902353}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "literal_eval(str(data[0:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "class Resource:\n",
    "    def __init__(self):\n",
    "        self.dt = datetime.now()\n",
    "        self.handle = open(f'C:\\\\TEMP\\\\ABC')\n",
    "        \n",
    "    def update(self):\n",
    "        \n",
    "        \n",
    "    def handle(self):\n",
    "        now = datetime.now()\n",
    "        if now - self.dt > timedelta(seconds=5):\n",
    "            self.dt = now\n",
    "\n",
    "    def __del__(self):\n",
    "        print(f'- ({type(self).counter} -> {type(self).counter-1})')\n",
    "        type(self).counter -= 1\n",
    "\n",
    "\n",
    "class Animal:\n",
    "    def __init__(self):\n",
    "        self.name = 'Monkey'\n",
    "        self.resource = Resource()\n",
    "        \n",
    "    def make_sound(self):\n",
    "        print('HoHoHo')\n",
    "        \n",
    "def foo():\n",
    "    anm1 = Animal()\n",
    "    try:\n",
    "        h = 1/0\n",
    "    except:\n",
    "        del anm1\n",
    "    return\n",
    "        \n",
    "\n",
    "foo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\Pontus\\Documents\\bitmexdata\\2021-02-04%BCHUSD%quote\", 'rb') as f:\n",
    "    gg = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'timestamp': '2021-02-04T19:33:57.020Z',\n",
       " 'symbol': 'XBTUSD',\n",
       " 'bidSize': 616147,\n",
       " 'bidPrice': 37228.5,\n",
       " 'askPrice': 37229,\n",
       " 'askSize': 229550}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
